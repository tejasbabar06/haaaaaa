GENERAL INFORMATION
Course Name : Apache Spark Mastery - Data Engineering with PySpark
Batch Schedule : 16-Aug-2025   To   17-Sep-2025
Schedule : Mon-Sat
Duration : 50 hrs.
Timings : 7:00 PM  To  9:00 PM
Fees : Rs. 14900/-(Inc.18% GST)

COURSE DETAILS

[Syllabus]
Section 1: Spark Architecture & Internals
- Distributed Computing Fundamentals
  - RDD lineage, DAG scheduler, lazy evaluation
  - Cluster managers overview
- Spark 4.x Updates
  - Adaptive Query Execution (AQE) enhancements
  - Catalyst optimizer improvements
- Performance Tuning
  - Joins
  - Partitioning, broadcast variables
  - Memory management
Section 2: PySpark DataFrames & SQL
- Data Manipulation
  - Complex types (JSON, arrays, maps)
  - Window functions, pivot tables, UDFs/Pandas UDFs
- Spark SQL Deep Dive
  - Temp views, catalog API, Hive metastore integration
  - SQL syntax for Delta Lake operations
- Execution Plans
  - Reading `explain()` output
  - Predicate pushdown, partition pruning
Section 3: Incremental Data Processing & Apache Kafka
- Structured Streaming
  - Event-time processing, watermarking, state management
  - Kafka integration (source/sink)
- Delta Lake Essentials
  - ACID transactions
  - Schema evolution
Section 4: Spark Optimizations
- Catalyst Internals
  - Logical vs. physical plans
  - Custom optimization extensions
- Performance Best Practices
  - File formats (Parquet/Delta)
  - Resource allocation (executors/cores)
Section 5: Databricks Lakehouse Platform
- Lakehouse fundamentals
- Workspace Navigation
  - DBFS, clusters, notebooks
- Delta Lake UI
  - Viewing table history/schema
- Data Governance
  - Unity Catalog basics (no Admin tasks)
Section 6: Apache Kafka Fundamentals  
- Architecture
  - Brokers, topics, partitions, consumer groups
- Spark-Kafka Integration
  - Structured Streaming with Kafka
  - Job execution
Section 7: Spark ML Introduction
- MLlib Workflow
  - Transformers vs. estimators, pipelines
  - Feature engineering (VectorAssembler, StringIndexer)
- Model Training
  - Regression demo (no hyperparameter tuning)
Section 8: Capstone Project
- Pipeline implementation
- Domain Examples: IoT monitoring, retail analytics
  CLICK TO REGISTER

[Outcome]
Master PySpark DataFrames/SQL for batch & stream processing
Build optimized pipelines using Catalyst insights
Understand Spark job execution internals
Understand Apache Kafka and Integrate with Spark
Hands-on implementation of capstone project
Certification-ready skills
CLICK TO REGISTER


BATCH SCHEDULE

Batch 1
Sr.No : 1
Batch Code : Spark-O-04
Start Date : 16-Aug-2025
End Date : 17-Sep-2025
Time : 7:00 PM  To  9:00 PM
